# rag-chatbot-mlops

# ğŸ§  RAG Chatbot (Retrieval-Augmented Generation)

A full-stack **AI-powered chatbot** that answers questions from your uploaded documents (PDF, CSV, DOCX, TXT) using **retrieval-augmented generation (RAG)**. Runs **100% locally** or optionally via OpenAI/Claude.

---

## ğŸš€ Features

- Upload documents and ask questions about them
- Built-in document chunking, embedding (FAISS + SBERT)
- LLM toggle: OpenAI, Claude, or Ollama (Mistral)
- Flask-based chat UI
- Dockerized + tested + CI/CD ready

---

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI + FAISS + SentenceTransformers
- **Frontend**: Flask
- **LLMs**: Mistral via Ollama | OpenAI | Claude (Anthropic)
- **Embeddings**: `all-MiniLM-L6-v2`
- **Testing**: `pytest`
- **Monitoring**: Prometheus-ready (optional)
- **CI**: GitHub Actions

---

## ğŸ“ Project Structure

```bash
rag-chatbot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ui/               # Flask frontend
â”‚   â”œâ”€â”€ api/              # Optional FastAPI endpoints
â”‚   â”œâ”€â”€ ingestion/        # File parsing & chunking
â”‚   â”œâ”€â”€ vectorstore/      # FAISS logic
â”‚   â”œâ”€â”€ llm/              # LLM integrations
â”‚   â”œâ”€â”€ utils/            # Shared helpers
â”œâ”€â”€ tests/                # Unit & integration tests
â”œâ”€â”€ docker/               # Docker + docker-compose
â”œâ”€â”€ data/                 # Uploaded files + indexes
